{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a77258",
   "metadata": {},
   "source": [
    "# Imports and Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bc68345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive 3d plots?\n",
    "interactive=True\n",
    "\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import glob\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "if interactive:\n",
    "    %matplotlib qt\n",
    "\n",
    "# Set paths\n",
    "baseDir = os.path.join(os.getcwd(),'..')\n",
    "codeDir = os.path.join(baseDir, 'code')\n",
    "dataDir = os.path.join(baseDir, 'data')\n",
    "stimDir = os.path.join(baseDir, 'BOLD5000_Stimuli_Shared')\n",
    "\n",
    "N_TUNING_CURVES = 8\n",
    "\n",
    "qualtricsData = pd.read_csv(os.path.join(dataDir, \"qualtricsDataClean.csv\"),index_col='participant')\n",
    "masterData = pd.read_csv(os.path.join(dataDir, \"masterDataClean.csv\"),low_memory=False,index_col='participant')\n",
    "lingDirectionsAverage = pd.read_csv(os.path.join(dataDir, \"lingDirectionsAverage.csv\"),index_col='presentedImage')\n",
    "lingDirectionsParticipant = pd.read_csv(os.path.join(dataDir, \"lingDirectionsParticipant.csv\"),index_col=['presentedImage','participant'])\n",
    "analogDirectionsParticipant = pd.read_csv(os.path.join(dataDir, f'analogData_{N_TUNING_CURVES}_bins_Participant.csv'),index_col=['presentedImage','participant'])\n",
    "analogDirectionsAverage = pd.read_csv(os.path.join(dataDir, f'analogData_{N_TUNING_CURVES}_bins_Average.csv'),index_col='presentedImage')\n",
    "\n",
    "# Test that lists of images match each other\n",
    "image_list_analog = analogDirectionsAverage.index.to_list()\n",
    "image_list_ling = lingDirectionsAverage.index.to_list()\n",
    "\n",
    "assert(image_list_analog==image_list_ling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f20cddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ahead</th>\n",
       "      <th>right</th>\n",
       "      <th>left</th>\n",
       "      <th>sharp_right</th>\n",
       "      <th>slight_right</th>\n",
       "      <th>slight_left</th>\n",
       "      <th>sharp_left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presentedImage</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATM1.jpg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATM4.jpg</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HorseRaceTrack.jpg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RVinside2.jpg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShowJumping7.jpg</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ahead     right      left  sharp_right  slight_right  \\\n",
       "presentedImage                                                                \n",
       "ATM1.jpg            0.000000  0.250000  0.500000         0.25      0.000000   \n",
       "ATM4.jpg            0.714286  0.000000  0.142857         0.00      0.142857   \n",
       "HorseRaceTrack.jpg  0.000000  0.000000  0.250000         0.50      0.000000   \n",
       "RVinside2.jpg       1.000000  0.142857  0.000000         0.00      0.285714   \n",
       "ShowJumping7.jpg    0.750000  0.500000  0.500000         0.00      0.250000   \n",
       "\n",
       "                    slight_left  sharp_left  \n",
       "presentedImage                               \n",
       "ATM1.jpg               0.000000    0.500000  \n",
       "ATM4.jpg               0.285714    0.142857  \n",
       "HorseRaceTrack.jpg     0.250000    0.500000  \n",
       "RVinside2.jpg          0.142857    0.000000  \n",
       "ShowJumping7.jpg       0.500000    0.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1be52ebe",
   "metadata": {},
   "source": [
    "# Spearman Correlation between the Analog and Linguisitic Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1406faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Similarity between Linguistic and Analog Data\n",
    "def upper(df):\n",
    "    try:\n",
    "        assert(type(df)==np.ndarray)\n",
    "    except:\n",
    "        if type(df)==pd.DataFrame:\n",
    "            df = df.values\n",
    "        else:\n",
    "            raise TypeError('Must be np.ndarray or pd.DataFrame')\n",
    "    mask = np.triu_indices(df.shape[0], k=1)\n",
    "    return df[mask]\n",
    "\n",
    "# Spearman Similarity Between Two Cosine Similarity Matrix\n",
    "def calculateSimilarity(N_TUNING_CURVES):\n",
    "    df_analog = pd.read_csv(os.path.join(dataDir, f'analogData_{N_TUNING_CURVES}_bins_Average.csv'),index_col=0)\n",
    "    df_ling = pd.read_csv(os.path.join(dataDir, f'lingDirectionsAverage.csv'),index_col=0)\n",
    "    \n",
    "    df_analog_similarity = pd.DataFrame(cosine_similarity(df_analog),index=df_analog.index,columns=df_analog.index)\n",
    "    df_ling_similarity = pd.DataFrame(cosine_similarity(df_ling),index=df_ling.index,columns=df_ling.index)\n",
    "    \n",
    "    analog_upper = upper(df_analog_similarity) \n",
    "    ling_upper = upper(df_ling_similarity)\n",
    "    \n",
    "    # Now lets measure the Spearman similarity\n",
    "    result = stats.spearmanr(analog_upper,ling_upper)\n",
    "    corr = result.correlation\n",
    "    p_val = result.pvalue \n",
    "    print(f'Spearman Correlation: Analog {N_TUNING_CURVES} tuning curves and linguistic averages, r = {corr:.4f}, p = {p_val:.4f}')\n",
    "    return result,analog_upper,ling_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bfb815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: Analog 16 tuning curves and linguistic averages, r = 0.4029, p = 0.0000\n",
      "Spearman Correlation: Analog 8 tuning curves and linguistic averages, r = 0.4033, p = 0.0000\n",
      "Spearman Correlation: Analog 16 tuning curves and linguistic averages, r = 0.4029, p = 0.0000\n",
      "Spearman Correlation: Analog 37 tuning curves and linguistic averages, r = 0.3941, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Printing Similarity Between the different Analog and Linguistic Cosine Similarity Matrix\n",
    "\n",
    "result_16,analog_upper,ling_upper = calculateSimilarity(16)\n",
    "\n",
    "list_tuning_curves=[8,16,37]\n",
    "for i in list_tuning_curves:\n",
    "    calculateSimilarity(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7799b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "index = np.arange(len(analog_upper))\n",
    "corrs = []\n",
    "for i in np.arange(1,100):\n",
    "    random.shuffle(index)\n",
    "    result = stats.spearmanr(analog_upper[index],ling_upper)\n",
    "    corrs.append(result.correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a41b8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4029312207963288\n"
     ]
    }
   ],
   "source": [
    "print(result_16.correlation)\n",
    "plt.hist(corrs)\n",
    "plt.axvline(x=result_16.correlation,color='red',linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3b94b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "# Optimal number Of clusters\n",
    "def OptimalClusterElbowMethod(df,max_clusters=15):\n",
    "    cs = []\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i in range(1, max_clusters):\n",
    "        kmeans = KMeans(n_clusters = i, init = 'k-means++',random_state=seed)\n",
    "        kmeans.fit(df)\n",
    "        cs.append(kmeans.inertia_)\n",
    "    \n",
    "    # Plot fits by cluster number\n",
    "    plt.plot(range(1, max_clusters), cs)\n",
    "    plt.title('The Elbow Method')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.show()\n",
    "    \n",
    "# Cluster the Data into 3 groups.\n",
    "def clustering(df, clusters, show_elbow=True):\n",
    "    \n",
    "    if show_elbow:\n",
    "        OptimalClusterElbowMethod(df)\n",
    "\n",
    "    # Number of Optimized clusters here would be 3.\n",
    "    # defining the kmeans function with initialization as k-means++\n",
    "    kmeans = KMeans(n_clusters=clusters, init='k-means++',random_state=seed)\n",
    "\n",
    "    # fitting the k means algorithm on scaled data\n",
    "    kmeans.fit(df)\n",
    "\n",
    "    pred = kmeans.predict(df)\n",
    "    df['cluster'] = pred\n",
    "    df['cluster'].value_counts()\n",
    "    \n",
    "\n",
    "    \n",
    "    #Getting unique labels\n",
    "    label = np.unique(pred)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a47926",
   "metadata": {},
   "source": [
    "# Clustering Linguistic and analog Data and Plot the average Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88341f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the Clustering by taking the average and merge into one \n",
    "# right, slight_right and sharp_right merge into right_average \n",
    "# left, slight_left and sharp_left merge into left_average \n",
    "# Including the Ahead in the the Right Side\n",
    "\n",
    "def plotClustersData(df,clusters):\n",
    "    \n",
    "    df = clustering(df, clusters)\n",
    "    \n",
    "    print(df.groupby(['cluster']).mean())\n",
    "    \n",
    "    colors = ['blue','orange','purple','red','green','yellow','orange','black','magenta','pink','grey']\n",
    "\n",
    "    assert(clusters < len(colors))\n",
    "    \n",
    "    # Creating figure\n",
    "    fig = plt.figure(figsize = (16, 9))\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "    # Add x, y gridlines\n",
    "    ax.grid(visible = True, color ='grey',\n",
    "            linestyle ='-.', linewidth = 0.3,\n",
    "            alpha = 0.2)\n",
    "    \n",
    "    df['right_average'] = df.loc[:, [\"right\",\"sharp_right\",\"slight_right\"]].mean(axis = 1)\n",
    "    df['left_average'] = df.loc[:, [\"left\",\"sharp_left\",\"slight_left\",]].mean(axis = 1)\n",
    "\n",
    "    # Creating plot\n",
    "    df0 = df[df['cluster'] == 0]\n",
    "    sctt = ax.scatter3D(df0['right_average'],\n",
    "                        df0['left_average'], \n",
    "                        df0['ahead'],\n",
    "                        alpha = 0.8,\n",
    "                        c = colors[0],\n",
    "                        label=f'1 Cluster')\n",
    "\n",
    "    #Print the Clusters \n",
    "    for i in np.arange(1,clusters):\n",
    "        df_i = df[df['cluster'] == i]\n",
    "\n",
    "    \n",
    "        sctt=ax.scatter3D(df_i['right_average'],\n",
    "                  df_i['left_average'], \n",
    "                  df_i['ahead'],\n",
    "                  alpha = 0.8,\n",
    "                  c = colors[i],\n",
    "                  label=f'{i} Cluster')\n",
    "    \n",
    "    plt.title(\"Average direction by cluster\")\n",
    "    ax.set_xlabel('Right Average', fontweight ='bold')\n",
    "    ax.set_ylabel('Left Average', fontweight ='bold')\n",
    "    ax.set_zlabel('Ahead Average', fontweight ='bold')\n",
    "    ax.view_init(0,70)\n",
    "    \n",
    "    # show plot\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35db1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClustersData(lingDirectionsAverage,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2ec3c",
   "metadata": {},
   "source": [
    "# SVM Classification for Prediction on Analog Data and Linguistic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b5ab762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.4600\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53        43\n",
      "           1       0.52      0.50      0.51        24\n",
      "           2       0.33      0.33      0.33        33\n",
      "\n",
      "    accuracy                           0.46       100\n",
      "   macro avg       0.46      0.46      0.46       100\n",
      "weighted avg       0.46      0.46      0.46       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.4200\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.42      0.41        33\n",
      "           1       0.48      0.58      0.53        24\n",
      "           2       0.36      0.36      0.36        25\n",
      "           3       0.50      0.28      0.36        18\n",
      "\n",
      "    accuracy                           0.42       100\n",
      "   macro avg       0.43      0.41      0.41       100\n",
      "weighted avg       0.42      0.42      0.41       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.3700\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40        24\n",
      "           1       0.42      0.44      0.43        18\n",
      "           2       0.20      0.06      0.09        17\n",
      "           3       0.43      0.40      0.42        25\n",
      "           4       0.35      0.38      0.36        16\n",
      "\n",
      "    accuracy                           0.37       100\n",
      "   macro avg       0.35      0.36      0.34       100\n",
      "weighted avg       0.35      0.37      0.35       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.5300\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.51        18\n",
      "           1       0.38      0.38      0.38         8\n",
      "           2       0.70      0.88      0.78        24\n",
      "           3       0.38      0.38      0.38        16\n",
      "           4       0.38      0.28      0.32        18\n",
      "           5       0.67      0.50      0.57        16\n",
      "\n",
      "    accuracy                           0.53       100\n",
      "   macro avg       0.50      0.49      0.49       100\n",
      "weighted avg       0.52      0.53      0.52       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.4300\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.17      0.18        12\n",
      "           1       0.32      0.44      0.37        18\n",
      "           2       0.59      0.83      0.69        24\n",
      "           3       0.50      0.44      0.47        16\n",
      "           4       0.50      0.31      0.38        16\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.25      0.17      0.20         6\n",
      "\n",
      "    accuracy                           0.43       100\n",
      "   macro avg       0.34      0.34      0.33       100\n",
      "weighted avg       0.40      0.43      0.40       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.3200\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.29      0.24         7\n",
      "           1       0.41      0.50      0.45        24\n",
      "           2       0.36      0.42      0.38        12\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.50      0.38      0.43        16\n",
      "           5       0.33      0.17      0.22        18\n",
      "           6       0.18      0.33      0.24         6\n",
      "           7       0.20      0.22      0.21         9\n",
      "\n",
      "    accuracy                           0.32       100\n",
      "   macro avg       0.27      0.29      0.27       100\n",
      "weighted avg       0.33      0.32      0.31       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.3500\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.38      0.24         8\n",
      "           1       0.40      0.33      0.36        18\n",
      "           2       0.47      0.58      0.52        24\n",
      "           3       0.33      0.22      0.27         9\n",
      "           4       0.29      0.25      0.27         8\n",
      "           5       0.22      0.17      0.19        12\n",
      "           6       0.38      0.43      0.40         7\n",
      "           7       0.33      0.17      0.22         6\n",
      "           8       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.35       100\n",
      "   macro avg       0.33      0.31      0.31       100\n",
      "weighted avg       0.36      0.35      0.34       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.3000\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.18      0.15        11\n",
      "           1       0.18      0.29      0.22         7\n",
      "           2       0.09      0.08      0.09        12\n",
      "           3       0.50      0.33      0.40         9\n",
      "           4       0.25      0.12      0.17         8\n",
      "           5       0.58      0.58      0.58        24\n",
      "           6       0.27      0.38      0.32         8\n",
      "           7       0.17      0.12      0.14         8\n",
      "           8       0.40      0.29      0.33         7\n",
      "           9       0.17      0.17      0.17         6\n",
      "\n",
      "    accuracy                           0.30       100\n",
      "   macro avg       0.27      0.25      0.26       100\n",
      "weighted avg       0.32      0.30      0.30       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 7)\n",
      "(100, 7)\n",
      "Model accuracy score: 0.2900\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.25      0.23        12\n",
      "           1       0.27      0.38      0.32         8\n",
      "           2       0.29      0.22      0.25         9\n",
      "           3       0.25      0.14      0.18         7\n",
      "           4       0.11      0.17      0.13         6\n",
      "           5       0.38      0.55      0.44        11\n",
      "           6       0.25      0.33      0.29         9\n",
      "           7       0.25      0.14      0.18         7\n",
      "           8       0.40      0.25      0.31         8\n",
      "           9       0.29      0.25      0.27         8\n",
      "          10       0.45      0.33      0.38        15\n",
      "\n",
      "    accuracy                           0.29       100\n",
      "   macro avg       0.29      0.27      0.27       100\n",
      "weighted avg       0.30      0.29      0.29       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ClassificationData(df1,df2,clusters,show_plot=False):\n",
    "    df1_cluster = clustering(df1,clusters,show_elbow=False)\n",
    "    df2_cluster = clustering(df2,clusters,show_elbow=False)\n",
    "    \n",
    "    \n",
    "    # Declare feature vector and target variable\n",
    "    X = df1_cluster.drop(['cluster'], axis=1)\n",
    "    y = df2_cluster['cluster']\n",
    "\n",
    "    # split X and y into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y )\n",
    "\n",
    "    # check the shape of X_train and X_test\n",
    "    print(\"Checking Shape of Data\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    # instantiate classifier with default hyperparameters\n",
    "    svc=SVC(kernel='rbf', C=10000.0) \n",
    "\n",
    "    # fit classifier to training set\n",
    "    svc.fit(X_train,y_train)\n",
    "\n",
    "    # make predictions on test set\n",
    "    y_pred=svc.predict(X_test)\n",
    "\n",
    "    # compute and print accuracy score\n",
    "    print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    # Print the Confusion Matrix and slice it into four pieces\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #print('Confusion matrix\\n\\n', cm)\n",
    "    \n",
    "    if show_plot:\n",
    "        plot_confusion_matrix(svc,X_test,y_test)\n",
    "\n",
    "    #Print the Classification Report\n",
    "    print (\"Classification Report is\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return accuracy_score(y_test,y_pred)\n",
    "    \n",
    "scores = []\n",
    "for i in np.arange(3,12):\n",
    "    scores.append(ClassificationData(analogDirectionsAverage,lingDirectionsAverage,i,False))\n",
    "    \n",
    "fig = plt.figure(figsize = (16, 9))\n",
    "plt.plot(scores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf53ad9",
   "metadata": {},
   "source": [
    "# Classifier on Analog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f962c31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.9200\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        36\n",
      "           1       0.91      1.00      0.95        31\n",
      "           2       0.97      0.88      0.92        33\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8700\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82        36\n",
      "           1       0.93      0.93      0.93        15\n",
      "           2       0.85      0.88      0.87        33\n",
      "           3       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.89      0.89      0.89       100\n",
      "weighted avg       0.87      0.87      0.87       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.9300\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       0.97      0.88      0.92        33\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       0.91      0.95      0.93        21\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.94      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.9000\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       0.86      0.82      0.84        22\n",
      "           2       0.93      0.81      0.87        16\n",
      "           3       0.93      0.96      0.95        27\n",
      "           4       0.86      1.00      0.92         6\n",
      "           5       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.90      0.91      0.90       100\n",
      "weighted avg       0.90      0.90      0.90       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.9200\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        14\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.94      1.00      0.97        15\n",
      "           3       0.90      0.86      0.88        22\n",
      "           4       0.83      1.00      0.91        10\n",
      "           5       1.00      0.94      0.97        17\n",
      "           6       0.82      0.88      0.85        16\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.9100\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        22\n",
      "           1       1.00      0.83      0.91         6\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      0.94      0.97        16\n",
      "           4       0.94      1.00      0.97        15\n",
      "           5       0.62      0.83      0.71         6\n",
      "           6       1.00      0.75      0.86         8\n",
      "           7       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.91       100\n",
      "   macro avg       0.91      0.88      0.89       100\n",
      "weighted avg       0.92      0.91      0.91       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8800\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.80      0.73      0.76        11\n",
      "           2       0.77      0.91      0.83        11\n",
      "           3       0.93      0.93      0.93        15\n",
      "           4       0.89      1.00      0.94        17\n",
      "           5       0.94      0.94      0.94        16\n",
      "           6       1.00      0.80      0.89        10\n",
      "           7       1.00      0.67      0.80         6\n",
      "           8       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.88      0.85      0.86       100\n",
      "weighted avg       0.89      0.88      0.88       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8500\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.67      1.00      0.80         8\n",
      "           2       0.94      1.00      0.97        15\n",
      "           3       0.86      0.67      0.75         9\n",
      "           4       0.89      1.00      0.94        17\n",
      "           5       0.73      0.73      0.73        11\n",
      "           6       1.00      0.80      0.89        10\n",
      "           7       0.82      0.82      0.82        11\n",
      "           8       0.67      0.57      0.62         7\n",
      "           9       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.86      0.83      0.83       100\n",
      "weighted avg       0.86      0.85      0.85       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8400\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.75      0.82      0.78        11\n",
      "           2       0.90      1.00      0.95         9\n",
      "           3       0.78      0.70      0.74        10\n",
      "           4       0.75      0.50      0.60         6\n",
      "           5       0.77      0.91      0.83        11\n",
      "           6       0.80      0.80      0.80        10\n",
      "           7       1.00      0.88      0.93         8\n",
      "           8       0.83      0.71      0.77         7\n",
      "           9       0.80      0.67      0.73         6\n",
      "          10       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.83      0.82      0.82       100\n",
      "weighted avg       0.84      0.84      0.84       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in np.arange(3,12):\n",
    "    scores.append(ClassificationData(analogDirectionsAverage, analogDirectionsAverage, i))\n",
    "    \n",
    "fig = plt.figure(figsize = (16, 9))\n",
    "plt.plot(scores)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97ffac",
   "metadata": {},
   "source": [
    "# Classifier on Linguistic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "401db739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8900\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        33\n",
      "           1       0.97      0.84      0.90        38\n",
      "           2       0.85      1.00      0.92        29\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.89      0.90      0.89       100\n",
      "weighted avg       0.90      0.89      0.89       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8800\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88         9\n",
      "           1       0.86      0.83      0.84        29\n",
      "           2       0.96      0.93      0.95        29\n",
      "           3       0.81      0.91      0.86        33\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.91      0.86      0.88       100\n",
      "weighted avg       0.89      0.88      0.88       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8900\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.86      0.92      0.89        13\n",
      "           2       0.90      0.97      0.93        29\n",
      "           3       0.93      0.79      0.85        33\n",
      "           4       0.83      0.94      0.88        16\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.88      0.90      0.89       100\n",
      "weighted avg       0.89      0.89      0.89       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.9000\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.97      0.97      0.97        29\n",
      "           3       0.93      0.88      0.90        16\n",
      "           4       0.76      0.76      0.76        17\n",
      "           5       0.88      0.94      0.91        16\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.89      0.89      0.89       100\n",
      "weighted avg       0.90      0.90      0.90       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8200\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87        16\n",
      "           1       0.83      0.86      0.85        29\n",
      "           2       0.73      1.00      0.84         8\n",
      "           3       0.72      0.76      0.74        17\n",
      "           4       1.00      0.77      0.87        13\n",
      "           5       0.67      0.75      0.71         8\n",
      "           6       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.82      0.82      0.81       100\n",
      "weighted avg       0.83      0.82      0.82       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8800\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       0.93      0.88      0.90        16\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.75      0.88      0.81        17\n",
      "           5       1.00      1.00      1.00        13\n",
      "           6       0.86      0.75      0.80         8\n",
      "           7       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.88      0.88      0.88       100\n",
      "weighted avg       0.89      0.88      0.88       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8900\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84         9\n",
      "           1       0.67      0.89      0.76         9\n",
      "           2       1.00      0.95      0.98        21\n",
      "           3       1.00      0.75      0.86        16\n",
      "           4       1.00      0.92      0.96        13\n",
      "           5       0.80      1.00      0.89         8\n",
      "           6       1.00      0.75      0.86         8\n",
      "           7       0.89      1.00      0.94         8\n",
      "           8       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.88      0.89      0.88       100\n",
      "weighted avg       0.91      0.89      0.89       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8900\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78         8\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      0.88      0.93         8\n",
      "           4       1.00      0.89      0.94         9\n",
      "           5       0.91      1.00      0.95        21\n",
      "           6       0.89      0.89      0.89         9\n",
      "           7       0.89      0.89      0.89         9\n",
      "           8       1.00      0.50      0.67         8\n",
      "           9       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.90      0.87      0.87       100\n",
      "weighted avg       0.90      0.89      0.89       100\n",
      "\n",
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.8500\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "           2       1.00      1.00      1.00        21\n",
      "           3       0.86      0.75      0.80         8\n",
      "           4       0.89      1.00      0.94         8\n",
      "           5       1.00      1.00      1.00         7\n",
      "           6       1.00      0.75      0.86         8\n",
      "           7       0.78      0.88      0.82         8\n",
      "           8       0.67      0.25      0.36         8\n",
      "           9       0.80      0.89      0.84         9\n",
      "          10       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.84      0.83      0.81       100\n",
      "weighted avg       0.86      0.85      0.84       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in np.arange(3,12):\n",
    "    scores.append(ClassificationData(lingDirectionsAverage, lingDirectionsAverage, i))\n",
    "    \n",
    "fig = plt.figure(figsize = (16, 9))\n",
    "plt.plot(np.arange(3,12),scores)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d9d1b",
   "metadata": {},
   "source": [
    "# Cross-classifying Analog and Linguistic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b70f8bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Shape of Data\n",
      "(400, 9)\n",
      "(100, 9)\n",
      "Model accuracy score: 0.5700\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63        43\n",
      "           1       0.50      0.35      0.41        20\n",
      "           2       0.55      0.59      0.57        37\n",
      "\n",
      "    accuracy                           0.57       100\n",
      "   macro avg       0.55      0.53      0.54       100\n",
      "weighted avg       0.57      0.57      0.56       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevenweisberg\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassificationData(lingDirectionsAverage, analogDirectionsAverage, 3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca80c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
